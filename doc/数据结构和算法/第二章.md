# 时间复杂度与空间复杂度
数据结构和算法本生解决的就是「快」和「省」的问题，那就是如何让代码跑得快，还能节省存储空间。
复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半。这就就像内功心法，上乘武功还需搭配牛逼心法。

## 大 O 复杂度表示法   
所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比
我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！
```
T(n) = O(f(n))
```
其中 T(n) 它表示代码执行的时间，n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。
因为这是一个公式，所以用 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。

大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。
敲黑板了，表达的是变化趋势，并不是真正的执行时间。

当 n 很大时，你可以把它想象成 100000、1000000。而公式中的 **低阶、常量、系数** 三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了

## 时间复杂度分析
有三个比较实用的方法可以分享。

### 1. 只关注循环执行次数最多的一段代码

大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。
所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。擒贼先擒王就是这么回事。

段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。

```
int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```
其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。

循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。

### 2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

看如下代码可以先试着分析一下，然后再往下看跟我的分析思路是否一样。

```
int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }
 
   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1;
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
```

这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。

第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。

这里我要再强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

那第二段代码和第三段代码的时间复杂度是多少呢？答案是 O(n) 和 O(n^2^)，你应该能容易就分析出来，我就不啰嗦了。

综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n^2^)。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：

```
如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n)))
```

### 3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

刚刚说了一个加法原则，这里说的乘法原则，以此类推，你也应该能「猜到」公式。这个是效率最差的

```
int cal(int n) {
   int ret = 0;
   int i = 1;
   for(x=1; i <= n; x++){
       for(i = 1; i <= n; i++) {
           j = i;
           j++;
        }
	}
 }
```
我们单独看 cal() 函数。假设 5-8行的 只是一个普通的操作，那第 4 行的时间复杂度就是，T1(n) = O(n)。但 5-8 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是:O(n^2)

## 几种常见时间复杂度实例

虽然代码千差万别，但是常见的复杂度量级并不多。老弟稍微总结了一下，这些复杂度量级几乎涵盖了今后可以接触的所有代码的复杂度量级。

划重点了同学们。

>(1) 常量阶
>(2) 对数阶
>(3) 线性阶
>(4) 线性对数阶
>(5) 平方阶 O(n^2^)、立方阶 O(n^3^)…..k 次方阶 O(n^k^)
>(6) 指数阶 O(2^n^)
>(7) 阶乘阶 O(n!)

对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2^n) 和 O(n!)
当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我就不展开讲了。

我们主要来看几种常见的多项式时间复杂度。

### 1. O(1) 之一击必杀

首先我们必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。
一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。

### 2. O(logn)、O(nlogn)

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。

```
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```
根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：

2^0*2^1*2^2*2^3...2^x = n

所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2^x^=n 求解 x 这个问题我们想高中应该就学过了，我就不多说了。x=log~2~n，所以，这段代码的时间复杂度就是 O(log~2~n)。

我把代码稍微改下，这段代码的时间复杂度是多少？

```
i=1;
while (i <= n)  {
i = i * 3;
}
```
很简单就能看出来，这段代码的时间复杂度为 O(log~3~n)。
实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？

我们知道，对数之间是可以互相转换的，log3n 就等于 log~3~2 * log~2~n，所以 O(log~3~n) = O(C * log~2~n)，其中 C=log~3~2 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。所以，O(log~2~n) 就等于 O(log~3~n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。

如果你理解了我前面讲的 O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。

而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。实例如下：
内部 while循环是 O(logn) ,被外层 for 循环包起来。所以 就是 O(nlogn)
```
for(m = 1; m < n; m++) {
    i = 1;
    while(i < n) {
        i = i * 2;
    }
}
```

### 3. O(m+n)、O(m*n)

我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定。

```
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }
 
  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }
 
  return sum_1 + sum_2;
}
```
从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

### 4.线性阶O(n)
```
for(i=1; i<=n; i++) {
   j = i;
   j++;
}
```

### 平方阶O(n²)

```
for(x=1; i <= n; x++){
   for(i = 1; i <= n; i++) {
       j = i;
       j++;
    }
}
```

## 空复杂度分析

时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。




















